import streamlit as st
import pandas as pd
from scraper.main import scrape_jobs

st.title("ScrapeBomb ğŸ‹ v2.0")
st.markdown("ãƒ¬ãƒ¢ãƒ³ã‚’ãƒãƒã‚‹ã¨ã€æ±‚äººã‚µã‚¤ãƒˆã‚’ğŸ‹ãŒã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã¾ã™ã€‚")

# URLå…¥åŠ›
url = st.text_input("ğŸ”— æ±‚äººæ¤œç´¢URLï¼ˆä¾‹ï¼šhttps://æ±‚äººãƒœãƒƒã‚¯ã‚¹.com/ã€œï¼‰")

# é™¤å¤–ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›
raw_keywords = st.text_input("ğŸ§¹ é™¤å¤–ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šãƒ»å…¨è§’å…¥åŠ›OKãƒ»ã‚«ãƒ³ãƒã¯åŠè§’ã§ï¼‰", value="äººæ,æ´¾é£")
exclude_keywords = [kw.strip() for kw in raw_keywords.replace("ã€€", " ").split(",") if kw.strip()]

if st.button("ğŸ‹ ãƒ¬ãƒ¢ãƒ³ã‚’çµã‚‹ï¼") and url:
    with st.spinner("ãƒ¬ãƒ¢ãƒ³çµã‚Šä¸­..."):
        df = scrape_jobs(url, exclude_keywords)
        st.success("ğŸ‹ ãƒ¬ãƒ¢ãƒ³çµã‚Šå®Œäº†ï¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã—ã¾ã—ãŸã€‚")
        st.dataframe(df)

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        csv = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“¥ CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="job_list.csv", mime="text/csv")

